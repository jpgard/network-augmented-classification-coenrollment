# Copyright (C) 2017  The Regents of the University of Michigan
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see [http://www.gnu.org/licenses/].
# ========================================================================

## utility functions for building and evaluating structural models for [Gardner and Brooks 2017].
library(stepPlr)
library(randomForest)
library(glmnet)
library(nnet)
library(caret)
library(pROC)
source("preproc_utils.R")




## wrapper function to train models; if models_by is specified trains one model for each category of the specified variable
## df: input dataframe; must contain columns with names matching specified calues for models_by and outcome (DataFrame)
## models_by: factor column in df to create models by; one model will be created per level (character)
## outcome: variable in df to be predicted by models; all other variables are used as input to models (character)
## model_type: type of models to train; current options are "glmnet" (penalized logistic regression; sometimes has issues w/convergence), "glm", "rf" (random forest).
## returns: list of models of specified type; one per valid category of models_by in df.
build_mods <- function(df, models_by = "none", outcome = "CRSE_GRD_OFFCL_CD", model_type = "rf") {
    # initialize output data structure
    cat_mods = list() 
    # if models_by is specified, train one model per level of this variable
    # TODO: remove this is not using logistic regression; this isn't necessary for tree-based models
    if (models_by != "none") {
        mod_levels = levels(df[,models_by])
        # for each subject, fit one-vs-all model
        for (cat in mod_levels) {
            cat_mod_data = df[df[,models_by] == cat,]
            # drop any observations where that CRSE_GRD_OFFCL_CD is observed fewer than 8 times; this is necessary for glmnet cv and is applied to rf for consistency when combining models
            single_obs = cat_mod_data %>% ddply(.(CRSE_GRD_OFFCL_CD), summarize, freq = length(CRSE_GRD_OFFCL_CD)) %>% filter(freq <= 8)
            cat_mod_data = cat_mod_data[!(cat_mod_data$CRSE_GRD_OFFCL_CD %in% single_obs[,"CRSE_GRD_OFFCL_CD"]),]
            mod_x = select(cat_mod_data,-one_of(outcome, models_by))
            # drop any grade levels not observed in cat; note that this means model will not predict these levels
            mod_y = factor(cat_mod_data[,outcome])
            # only train models if there is more than one outcome that meets filtering criteria and there is non-zero variance in data matrix; otherwise skip
            if ((length(levels(mod_y)) > 1) & (sum(apply(mod_x, 2, function(x) length(unique(x)))) > ncol(mod_x))) {
                message("Training ", model_type, " model for ", cat)
                if (model_type == "rf") {
                    set.seed(48109)
                    cat.mod = randomForest(x = mod_x, y = mod_y, ntree = 100) #TODO: consider larger models w/more trees
                }
                if (model_type == "glmnet") {
                    # get best lambda using cv; then refit model on all data using this lambda
                    set.seed(2017)
                    cat.cv = cv.glmnet(x = as.matrix(mod_x), y = mod_y, family="multinomial", nfolds = 3)  #TODO: try increasing number of folds; this is mimimum
                    bestlambda = cat.cv$lambda.min
                    cat.mod = glmnet(x = as.matrix(mod_x), y = mod_y, family = "multinomial")
                }
                if (model_type == "glm") { 
                    # http://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/
                    mod_df = cbind(mod_x, mod_y)
                    names(mod_df)[ncol(mod_df)] <- "CRSE_GRD_OFFCL_CD"
                    # cat.mod = multinom(CRSE_GRD_OFFCL_CD ~ ., data = mod_df)
                    cat.mod = multinom(CRSE_GRD_OFFCL_CD ~ ., data = mod_df)
                }
                cat_mods[[cat]] = cat.mod
            }
        }
    # if models_by is not specified, train single model
    if (models_by == "none") {
        # TODO; train single model here; this will require a check for categorical variables with too many levels
    }
    }    
    return(cat_mods)
}

## wrapper function for predicting on a row of a test dataframe using the model list generated by build_mods.
## row: single-row dataframe with same format as training data used to generate models in mod_list (DataFrame). Note that for RandomForest prediction, this needs to have exact same factor labels (this should be accomplished by preprocessing in script).
## mod_list: list of models returned by build_mods() (list).
## models_by: column in row that was used to build models; this is used to look up corresponding model and is removed from row for prediction (character)
## outcomes: list of valid potential outcomes; model will not supply probabilities for outcomes not observed in training data so they are added post-prediction if necessary (character).
## method: method used in original call to build_mods; this is the type of model. Valid values: "rf", "glm" (character).
## returns: named vector of predicted probabilties for each class in outcomes.
get_pred <- function(row, mod_list, models_by = "SBJCT_CD", outcomes = c("A", "B", "C", "D"), method = "rf"){
    row_cat = as.character(row[,models_by])
    pred_row = select(row, -one_of(models_by))
    if (method == "rf") {
        pred = predict(mod_list[[row_cat]], pred_row, type = "prob")
        pred.out = sapply(outcomes, function(x) if (x %in% colnames(pred)) pred[,x] else 0)
    }
    if (method == "glm") {
        # this assumes multinom() model from nnet package
        pred = predict(mod_list[[row_cat]], row, "probs")
        pred.out = sapply(outcomes, function(x) if (x %in% names(pred)) pred[x] else 0)
    }
    return(list(pred.out))
}



## Make predictions/evaluate on data. Note: will only predict on elements of df which match filtering criteria of trained models; note that this filtering is typically applied by subject
## oa_df: object attribute data; this corresponds to OA(X) in model (DataFrame).
## la_df: link attribute data; this corresponds to LA(X) in model (DataFrame).
## la_nn_df: link attribute data for "nearest neighbors" or coenrolled students only; this coresonds to LA_nn(X) in model (DataFrame).
## oa_mods: object attribute models (list, each containing an object with a valid predict method).
## la_mods: link attribute models (list, each containing an object with a valid predict method).
## la_nn_mods: "object"nearest neighbor" or direct coenrollment attribute models (list, each containing an object with a valid predict method).
## pred_type: type of prediction; can be "flat", "struct", "struct_nn", "ensemble" (TODO). This selection determines which data needs to be supplied.
## models_by: column in row that was used to build models; should be identical for each _mods list.
## test_obs: number of observations to test on; will only limit predictions to the first test_obs rows of each dataframe (numeric).
## oa_preds: list of pre-computed OA probabilities; if these are not provided they are calculated directly but providing them saves substantial time.
## class_probs: class prior probabilities(table); see build_models.Rmd for example of how to calculate.
## probs: return dataframe of probabilities instead of predictions (logical).
## return: list with the prediction data for each type of model used, and the overall predictions for the model. Output depends on model type specifications.
##          if pred_type == "oa_preds", this function actually returns the predicted class probabilities, not just the overall prediction.
struct_predict <- function(oa_df, la_df = NULL, la_nn_df = NULL, oa_mods = NULL, la_mods = NULL, la_nn_mods = NULL, pred_type = "flat", models_by = "SBJCT_CD", test_obs = NULL, oa_preds = NULL, class_probs = NULL, probs = FALSE){
    # TODO: check oa_df and la_df; should have same number of rows if la_df is provided
    # TODO: check la_mods and oa_mods; should have smae length if la_mods is provided
    # TODO: check whether test_obs > nrow(oa_pred_df); if it is, return error and break (or set test_obs <- nrow(oa_pred_df) and send message)
    # filter data to only observations valid for prediction using names of models in oa_mods
    mod_cats = names(oa_mods)
    oa_pred_df = oa_df[oa_df[,models_by] %in% mod_cats,]
    if (is.null(test_obs)) test_obs = nrow(oa_pred_df)
    if (!is.null(la_df)) la_pred_df = la_df[la_df[,models_by] %in% mod_cats,]
    if (!is.null(la_nn_df)) la_nn_pred_df = la_nn_df[la_nn_df[,models_by] %in% mod_cats,]
    # generate predicted link probabilities if requested
    if (pred_type == "la_preds"|pred_type == "la_nn_preds") {
        la_preds = list()
        message("Generating link predictions")
        for (i in seq(1,test_obs)) {
            if (i %% 1000 == 0) print(paste("row", i, collapse = ' '))
            if (pred_type == "la_preds") {
                row = la_pred_df[i,]
                la_preds[i] <- get_pred(row, mod_list = la_mods, method = "glm")
            }
            else if (pred_type == "la_nn_preds") {
                row = la_nn_pred_df[i,]
                la_preds[i] <- get_pred(row, mod_list = la_nn_mods, method = "glm")
            }
        }
        # return pred df and preds
        if (pred_type == "la_preds") return(list("la_pred_df" = la_pred_df, "la_preds" = la_preds))
        else if (pred_type == "la_nn_preds") return(list("la_nn_pred_df" = la_nn_pred_df, "la_nn_preds" = la_preds))
    }
    # generate flat predictions if not provided
    if (is.null(oa_preds)){
        oa_preds = list()
        #for (i in seq_along(oa_preds)){
        message("Generating flat predictions")
        for (i in seq(1,test_obs)) {
            if (i %% 1000 == 0) print(paste("row", i, collapse = ' '))
            row = oa_pred_df[i,]
            oa_preds[i] <- get_pred(row, mod_list = oa_mods)
        }
    }
    if(pred_type == "oa_preds"){
        return(list("oa_pred_df" = oa_pred_df, "oa_preds" = oa_preds))
    }
    # generate and return predictions based on specified pred_type
    if(pred_type == "flat") {
        # only use oa predictions
        flat_preds = sapply(oa_preds, function(x) names(which.max(x)))
        return(list("oa_pred_df" = oa_pred_df, "preds" = flat_preds))
    }
    if(pred_type == "struct") {
        # make link attribute predictions, then multiply with object attribute predictions to get final prediction
        # TODO: this should be an apply function; something like below but generates error
        # la_preds = apply(la_pred_df, 1, function(x) get_pred(x, mod_list = la_mods))
        # TEST; eliminate later after implementing apply above
        message("Generating link-based predictions")
        la_preds = list()
        for (i in seq(1,test_obs)) {
            if (i %% 1000 == 0) print(paste("row", i, collapse = ' '))
            row = la_pred_df[i,]
            la_preds[i] <- get_pred(row, mod_list = la_mods, method = "glm")
        }
        # find max prediction
        struct_preds = mapply(function(x,y) names(which.max(x*y/class_probs)), oa_preds, la_preds)
        return(list("oa_pred_df" = oa_pred_df, "la_pred_df" = la_pred_df, "preds" = struct_preds))
    }
    if(pred_type == "struct_nn") {
        # make link attribute predictions, then multiply with object attribute predictions to get final prediction
        # TODO: this should be an apply function; something like below but generates error
        # la_preds = apply(la_pred_df, 1, function(x) get_pred(x, mod_list = la_mods))
        # TEST; eliminate later after implementing apply above
        message("Generating link-based predictions")
        la_preds = list()
        for (i in seq(1,test_obs)) {
            if (i %% 1000 == 0) print(paste("row", i, collapse = ' '))
            row = la_pred_df[i,]
            la_preds[i] <- get_pred(row, mod_list = la_mods, method = "glm")
        }
        message("Generating nn predictions")
        la_nn_preds = list()
        for (i in seq(1,test_obs)) {
            if (i %% 1000 == 0) print(paste("row", i, collapse = ' '))
            row = la_nn_pred_df[i,]
            la_nn_preds[i] <- get_pred(row, mod_list = la_nn_mods, method = "glm")
        }
        # find max prediction
        struct_preds = mapply(function(x,y,z) names(which.max(x*y*z/class_probs)), oa_preds, la_preds, la_nn_preds)
        return(list("oa_pred_df" = oa_pred_df, "la_pred_df" = la_pred_df, "la_nn_pred_df" = la_nn_pred_df, "preds" = struct_preds))
    }
    if(pred_type == "ensemble") {
        # TODO; this will require building one dataframe from oa_df, la_df, oa_preds, and la_preds, and then training a meta-learner (another rf; xgboost, etc) on this.
    }
}


## Construct DataFrame of model accuracy by subject.
## pred_df: test data used to generate preds; this is ground-truth and must include CRSE_GRD_OFFCL_CD column (DataFrame).
## preds: vector of predictions, one per rown in pred_df
acc_by_subject <- function(pred_df, preds) {
    acc = pred_df$CRSE_GRD_OFFCL_CD == preds
    subject_acc_df = data.frame("SBJCT_CD" = pred_df$SBJCT_CD, acc)
    df_out = ddply(subject_acc_df, .(SBJCT_CD), summarize, avc_acc = mean(acc))
    return(df_out)
}


## Construct DataFrame from list of individual dataframes of predictions from different models to be used for building meta-learner in blending.
# df_list: list of DataFrames; name of each entry should be a unique prefix for that model's predictions.
make_probe_df <- function(df_list, valid_grades = c("A", "B", "C", "D")) {
    probe_df_list = list()
    # give standardized names to each model's predictions using name in df_list element as prefix
    for (i in seq_along(df_list)) {
        prefix = names(df_list)[[i]]
        probe_df = data.frame(df_list[[i]])
        names(probe_df) <- paste0(prefix, valid_grades)
        probe_df_list[[i]] = probe_df
    }
    df_out = bind_cols(probe_df_list)
    return(df_out)
}

## create input matrix for neural net from probe predictions
## probe_pred_df: single dataframe from all probe predictions in ensemble model
make_nn_matrix <- function(probe_pred_df) {
    Y_nn = model.matrix(~probe_pred_df$CRSE_GRD_OFFCL_CD - 1)
    y_names = levels(probe_pred_df$CRSE_GRD_OFFCL_CD)
    colnames(Y_nn) = y_names
    X_nn = as.matrix(subset(probe_pred_df, select = -c(CRSE_GRD_OFFCL_CD)))
    x_names = colnames(X_nn)
    train_nn = cbind(X_nn, Y_nn)
    out_list = list("mx" = train_nn, "y_names" = y_names, "x_names" = x_names)
    return(out_list)
}


## compute predictions for a neural network model on dat
## nn: neuralnet object
## dat: matrix with input and binary output columns (one per output class); should match data passed to train nn.
predict_nn = function(nn, dat) {
    yhat = neuralnet::compute(nn, dat)$net.result
    yhat = apply(yhat, 1, which.max)-1
    return(yhat)
}

## fetch lots of multiclass evaluation metrics for labs and preds
## labs: vector of labels
## preds: vector of predictions
fetch_multiclass_metrics <- function(labs, preds, valid_labs = c("A", "B", "C", "D")){
    if(length(labs) != length(preds)) stop("Labels and predictions must be same length.")
    # coerce labs and preds to factor with same levels including all of valid_labs; this should handle any data type but may give unintended behavior for non-factor input data
    labs = factor(c(as.character(labs), valid_labs))[1:length(labs)]
    preds = factor(c(as.character(preds), valid_labs))[1:length(preds)]
    auc_temp = pROC::multiclass.roc(as.integer(labs), as.integer(preds))
    auc = as.numeric(auc_temp$auc)
    mcs = multiClassSummary(data = data.frame(obs = labs, pred = preds), lev = levels(labs))
    mcs %<>% t() %>% data.frame()
    df_out = cbind(mcs, data.frame("Multiclass_AUC" = auc))
    return(df_out)
}

## predict grade of students' previous GPA
## prev_term_cum_gpa: vector of students' previous term cumulative gpas
gpa_model_predict <- function(prev_term_cum_gpa){
    preds <- rep(NA, length(prev_term_cum_gpa))
    for (i in seq_along(preds)){
        gpa = prev_term_cum_gpa[i]
        if (gpa > 3.6) pred = "A"
        else if (gpa > 2.6) pred = "B"
        else if (gpa > 1.6) pred = "C"
        else pred = "D"
        preds[i] <- pred
    }
    return(preds)
}